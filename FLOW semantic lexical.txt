UPDATED FINAL SYSTEM FLOW — QUERY ANALYSIS AND RETRIEVAL (DYNAMIC WEIGHTS + SEMANTIC RELEVANCE FILTER)

1. Query Validation Phase

Extract words from the query (tokenized and lowercased).

Validate words using wordfreq (tl):

Word is valid if it has a positive frequency score.

Check for Filipino stopwords using stopwords-tl:

If all words are stopwords → mark as uninformative query.

If no valid Filipino words → mark as gibberish query.

If valid non-stopwords exist → proceed to next phase.

2. Lexical Presence Check

Compare valid query words across both sentence_text and meaning columns in the CSV.

Count lexical occurrences of each query word.

If words are sufficiently present → continue.

Otherwise → stop (not enough lexical presence).

3. Lexical & Semantic Scoring (Retrieve Single Sentence)

For each CSV entry:

Determine sentence length of sentence_text.

Apply dynamic weight calculation based on length:

Longer sentence → increase Semantic weight, decrease Lexical weight.

Shorter sentence → increase Lexical weight, decrease Semantic weight.

Compute Lexical Score → overlap/frequency between query and sentence_text.

Compute Semantic Score → cosine similarity between XLM-RoBERTa embeddings of the query and sentence_text.

Combine scores:

Total Score = (dynamic_lexical × Lexical) + (dynamic_semantic × Semantic)


Rank all sentences by Total Score.

Select the top-ranked sentence_text as the retrieved sentence.

4. Semantic Relevance Evaluation (Blocking Mechanism) ✅ (New Phase)

Compute maximum semantic similarity between the query and all candidate sentences.

If the maximum similarity score < threshold (e.g., 0.55):

Classify the query as semantically irrelevant to the corpus.

Output:

“No thematically or semantically relevant passage found.”


Stop further retrieval phases.

If the score ≥ threshold → proceed to neighbor expansion.

(Optional: dynamically adjust threshold based on query length or lexical presence.)

5. Neighbor Sentence Expansion (Paragraph Context Generation)

Identify neighbor sentences (previous and next rows relative to the retrieved sentence).

For each neighbor sentence:

Determine its length relative to the retrieved sentence.

Apply dynamic weighting:

Longer neighbor → higher Semantic weight, lower Lexical weight.

Shorter neighbor → higher Lexical weight, lower Semantic weight.

Compute Lexical Score → overlap between retrieved and neighbor sentences.

Compute Semantic Score → embedding similarity between them.

Combine scores to form total similarity:

Total Score = (dynamic_lexical × Lexical) + (dynamic_semantic × Semantic)


Include neighbors exceeding the similarity threshold.

Merge retrieved sentence + selected neighbors → paragraph context.

6. Thematic Exploration

For each entry in the meaning column:

Determine entry length relative to the retrieved sentence.

Apply dynamic weights:

Longer meaning → higher Semantic weight, lower Lexical weight.

Shorter meaning → higher Lexical weight, lower Semantic weight.

Compute Lexical Score (overlap/frequency).

Compute Semantic Score (embedding similarity).

Combine:

Total Score = (dynamic_lexical × Lexical) + (dynamic_semantic × Semantic)


Rank all meaning entries by Total Score.

Retrieve top meaning-based related sentences for thematic expansion.